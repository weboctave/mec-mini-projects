{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit 13.6 Capstone.\n",
    "I found a comparable project.  Here is a link to it.<br>\n",
    "Predicting Bad Housing Loans using Public Freddie Mac Data â€” a tutorial on working with imbalanced data\n",
    "https://towardsdatascience.com/predicting-bad-housing-loans-using-public-freddie-mac-data-a-tutorial-on-working-with-imbalanced-d2852c003996\n",
    "https://github.com/tsofoon/freddie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I attempted to replicate the project.  However, the data is too much to load into my computer.  I kept getting memory error in jupyter notebook.  \n",
    "Here is part of the code were I loaded the loan origination data into mysql.  The time series data was not able to load into mysql because of memory issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loan Level Data from http://www.freddiemac.com/research/datasets/sf_loanlevel_dataset.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read database credentials from file\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('mysql.properties')\n",
    "\n",
    "host=config.get('DatabaseSection', 'database.host')\n",
    "dbname=config.get('DatabaseSection', 'database.dbname')\n",
    "user=config.get('DatabaseSection', 'database.user')\n",
    "pwd=config.get('DatabaseSection', 'database.password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Origination Data File into Database\n",
    "loans and remittance table should be empty before loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup mysql db connection\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "\n",
    "sqlEngine = create_engine(f'mysql+pymysql://{user}:{pwd}@{host}/{dbname}', pool_recycle=3600)\n",
    "con = sqlEngine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFile(fileName, tableName, con, columns, data_type):\n",
    "    df = pd.read_csv('data/' + fileName, delimiter='|', header=None, names=columns, dtype = data_type)\n",
    "    if tableName == 'loans':\n",
    "        df['NUMBER_OF_UNITS'] = df['NUMBER_OF_UNITS'].str.strip()\n",
    "        df['NUMBER_OF_UNITS'] = np.where(df['NUMBER_OF_UNITS'] == '.', '99', df['NUMBER_OF_UNITS'])\n",
    "        df.to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "    elif tableName == 'remittance':\n",
    "        df['REMAINING_MONTHS_TO_MATURITY'] = df['REMAINING_MONTHS_TO_MATURITY'].str.strip()\n",
    "        df['REMAINING_MONTHS_TO_MATURITY'] = np.where(df['REMAINING_MONTHS_TO_MATURITY'] == '.', None, df['REMAINING_MONTHS_TO_MATURITY'])\n",
    "        df['REMAINING_MONTHS_TO_MATURITY'] = np.where(df['REMAINING_MONTHS_TO_MATURITY'] == '***', None, df['REMAINING_MONTHS_TO_MATURITY'])\n",
    "        df['CURRENT_DEFERRED_UPB'] = np.where(df['CURRENT_DEFERRED_UPB'] == '.', None, df['CURRENT_DEFERRED_UPB'])\n",
    "        df['NET_SALES_PROCEEDS'] = np.where(df['NET_SALES_PROCEEDS'] == 'U', None, df['NET_SALES_PROCEEDS'])\n",
    "        # need to split up the write as it overwhelm the laptop\n",
    "        df[df['CURRENT_ACTUAL_UPB']>=200000].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=180000) & (df['CURRENT_ACTUAL_UPB']<200000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=170000) & (df['CURRENT_ACTUAL_UPB']<180000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=150000) & (df['CURRENT_ACTUAL_UPB']<170000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=130000) & (df['CURRENT_ACTUAL_UPB']<150000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=120000) & (df['CURRENT_ACTUAL_UPB']<130000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=110000) & (df['CURRENT_ACTUAL_UPB']<120000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=100000) & (df['CURRENT_ACTUAL_UPB']<110000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=90000) & (df['CURRENT_ACTUAL_UPB']<100000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=80000) & (df['CURRENT_ACTUAL_UPB']<90000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=70000) & (df['CURRENT_ACTUAL_UPB']<80000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=60000) & (df['CURRENT_ACTUAL_UPB']<70000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=50000) & (df['CURRENT_ACTUAL_UPB']<60000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=40000) & (df['CURRENT_ACTUAL_UPB']<50000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']>=30000) & (df['CURRENT_ACTUAL_UPB']<40000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        df[(df['CURRENT_ACTUAL_UPB']<30000)].to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "        # df.to_sql(name=tableName, con=con, schema='mortgage', if_exists='append', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "originationFiles = ['historical_data_excl_', 'historical_data_'] # 1999Q1\n",
    "\n",
    "orig_columns=['CREDIT_SCORE', 'FIRST_PAYMENT_DATE', 'FIRST_TIME_HOMEBUYER', 'MATURITY_DATE', 'MSA', 'MI_PERCENT', 'NUMBER_OF_UNITS', \\\n",
    "              'OCCUPANCY_STATUS', 'ORIGINAL_CLTV', 'ORIGINAL_DTI', 'ORIGINAL_UPB', 'ORIGINAL_LTV', 'ORIGINAL_INTEREST_RATE', \\\n",
    "              'CHANNEL', 'PREPAYMENT_PENALTY_MORTGAGE', 'AMORTIZATION_TYPE', 'PROPERTY_STATE', 'PROPERTY_TYPE', 'POSTAL_CODE', \\\n",
    "              'LOAN_NUMBER', 'LOAN_PURPOSE', 'ORIGINAL_LOAN_TERM', 'NUMBER_OF_BORROWERS', 'SELLER_NAME', 'SERVICER_NAME', \\\n",
    "              'SUPER_CONFORMING', 'PREHARP_LOAN_NUMBER', 'PROGRAM_INDICATOR', 'HARP_INDICATOR', 'PROPERTY_VALUATION_METHOD', \\\n",
    "              'INTEREST_ONLY_INDICATOR']\n",
    "\n",
    "orig_data_type = {'HARP_INDICATOR':str, 'POSTAL_CODE': str, 'PREHARP_LOAN_NUMBER':str, 'PROGRAM_INDICATOR':str, \\\n",
    "                 'FIRST_PAYMENT_DATE':'Int32', 'FIRST_TIME_HOMEBUYER':str, 'MATURITY_DATE':'Int32', 'MSA':str, 'MI_PERCENT':np.int32,\\\n",
    "                 'ORIGINAL_LOAN_TERM':'Int16', 'NUMBER_OF_BORROWERS':'Int16', 'SUPER_CONFORMING':str, \\\n",
    "                 'PROPERTY_VALUATION_METHOD':'Int16', 'NUMBER_OF_UNITS':str}\n",
    "\n",
    "years = range(1999, 2005)\n",
    "qtrs = range(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing historical_data_excl_1999Q1.txt\n",
      "Processing historical_data_excl_1999Q2.txt\n",
      "Processing historical_data_excl_1999Q3.txt\n",
      "Processing historical_data_excl_1999Q4.txt\n",
      "Processing historical_data_excl_2000Q1.txt\n",
      "Processing historical_data_excl_2000Q2.txt\n",
      "Processing historical_data_excl_2000Q3.txt\n",
      "Processing historical_data_excl_2000Q4.txt\n",
      "Processing historical_data_excl_2001Q1.txt\n",
      "Processing historical_data_excl_2001Q2.txt\n",
      "Processing historical_data_excl_2001Q3.txt\n",
      "Processing historical_data_excl_2001Q4.txt\n",
      "Processing historical_data_excl_2002Q1.txt\n",
      "Processing historical_data_excl_2002Q2.txt\n",
      "Processing historical_data_excl_2002Q3.txt\n",
      "Processing historical_data_excl_2002Q4.txt\n",
      "Processing historical_data_excl_2003Q1.txt\n",
      "Processing historical_data_excl_2003Q2.txt\n",
      "Processing historical_data_excl_2003Q3.txt\n",
      "Processing historical_data_excl_2003Q4.txt\n",
      "Processing historical_data_excl_2004Q1.txt\n",
      "Processing historical_data_excl_2004Q2.txt\n",
      "Processing historical_data_excl_2004Q3.txt\n",
      "Processing historical_data_excl_2004Q4.txt\n",
      "Processing historical_data_1999Q1.txt\n",
      "Processing historical_data_1999Q2.txt\n",
      "Processing historical_data_1999Q3.txt\n",
      "Processing historical_data_1999Q4.txt\n",
      "Processing historical_data_2000Q1.txt\n",
      "Processing historical_data_2000Q2.txt\n",
      "Processing historical_data_2000Q3.txt\n",
      "Processing historical_data_2000Q4.txt\n",
      "Processing historical_data_2001Q1.txt\n",
      "Processing historical_data_2001Q2.txt\n",
      "Processing historical_data_2001Q3.txt\n",
      "Processing historical_data_2001Q4.txt\n",
      "Processing historical_data_2002Q1.txt\n",
      "Processing historical_data_2002Q2.txt\n",
      "Processing historical_data_2002Q3.txt\n",
      "Processing historical_data_2002Q4.txt\n",
      "Processing historical_data_2003Q1.txt\n",
      "Processing historical_data_2003Q2.txt\n",
      "Processing historical_data_2003Q3.txt\n",
      "Processing historical_data_2003Q4.txt\n",
      "Processing historical_data_2004Q1.txt\n",
      "Processing historical_data_2004Q2.txt\n",
      "Processing historical_data_2004Q3.txt\n",
      "Processing historical_data_2004Q4.txt\n"
     ]
    }
   ],
   "source": [
    "# iterate over the Origination Files\n",
    "for file in originationFiles:\n",
    "    for y, q in [(y,q) for y in years for q in qtrs]:\n",
    "        fileName = f'{file}{y}Q{q}.txt'\n",
    "        print('Processing ' + fileName)\n",
    "        loadDataFile(fileName, 'loans', con, orig_columns, orig_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileName='historical_data_1999Q1.txt'\n",
    "# df = pd.read_csv('data/' + fileName, delimiter='|', header=None, names=orig_columns, dtype = orig_data_type)\n",
    "# df.info()\n",
    "# # \n",
    "# # historical_data_excl_1999Q1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"NUMBER_OF_UNITS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"NUMBER_OF_UNITS\"]=='.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileName='historical_data_1999Q1.txt'\n",
    "# df = pd.read_csv('data/' + fileName, delimiter='|', header=None, names=orig_columns, dtype = orig_data_type)\n",
    "# df['NUMBER_OF_UNITS'] = df['NUMBER_OF_UNITS'] \n",
    "# df['NUMBER_OF_UNITS'] = np.where(df['NUMBER_OF_UNITS'] == '.', 99, df['NUMBER_OF_UNITS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_sql(name='loans', con=con, schema='mortgage', if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileName='historical_data_1999Q1.txt'\n",
    "# df = loadDataFile(fileName, 'loans', con, orig_columns, orig_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remitFiles = ['historical_data_excl_time_','historical_data_time_'] # 1999Q1\n",
    "\n",
    "# remit_columns=['LOAN_NUMBER', 'MONTHLY_REPORTING_PERIOD', 'CURRENT_ACTUAL_UPB', 'DELINQUENCY_STATUS', 'LOAN_AGE', \\\n",
    "#               'REMAINING_MONTHS_TO_MATURITY', 'REPURCHASE', 'MODIFICATION', 'ZERO_BALANCE_CODE', 'ZERO_BALANCE_EFFECTIVE_DATE', \\\n",
    "#               'CURRENT_INTEREST_RATE', 'CURRENT_DEFERRED_UPB', 'DUE_DATE_OF_LAST_PAID_INSTALLMENT', \\\n",
    "#               'MI_RECOVERIES', 'NET_SALES_PROCEEDS', 'NON_MI_RECOVERIES', 'EXPENSES', 'LEGAL_COSTS', 'MAINTENANCE_PRESERVATION_COSTS', \\\n",
    "#               'TAXES_AND_INSURANCE', 'MISCELLANEOUS_EXPENSES', 'ACTUAL_LOSS_CALCULATION', 'MODIFICATION_COST', 'STEP_MODIFICATION',\\\n",
    "#               'DEFERRED_PAYMENT_PLAN', 'ESTIMATED_LOAN_TO_VALUE', 'ZERO_BALANCE_REMOVAL_UPB', 'DELINQUENT_ACCRUED_INTEREST', \\\n",
    "#               'DELINQUENCY_DUE_TO_DISASTER', 'BORROWER_ASSISTANCE_STATUS_CODE']\n",
    "\n",
    "# remit_data_type = {'MODIFICATION':str, 'REPURCHASE': str, 'DELINQUENCY_STATUS':str, 'LOAN_NUMBER':str, \\\n",
    "#              'MONTHLY_REPORTING_PERIOD':'Int32', 'STEP_MODIFICATION':str, 'LOAN_AGE':'Int16', 'REMAINING_MONTHS_TO_MATURITY':str,\\\n",
    "#                    'ZERO_BALANCE_CODE':'Int16', 'ZERO_BALANCE_EFFECTIVE_DATE':'Int32', 'DUE_DATE_OF_LAST_PAID_INSTALLMENT':'Int32', \\\n",
    "#                   }\n",
    "\n",
    "# # NET_SALES_PROCEEDS has value of U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileName = 'historical_data_excl_time_1999Q1.txt'\n",
    "# df = loadDataFile(fileName, 'remittance', con, remit_columns, remit_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['REMAINING_MONTHS_TO_MATURITY'] == '***')]\n",
    "# df[(df['REMAINING_MONTHS_TO_MATURITY'] == '.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['CURRENT_ACTUAL_UPB']>=200000].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=170000) & (df['CURRENT_ACTUAL_UPB']<200000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=150000) & (df['CURRENT_ACTUAL_UPB']<170000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=130000) & (df['CURRENT_ACTUAL_UPB']<150000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=120000) & (df['CURRENT_ACTUAL_UPB']<130000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=110000) & (df['CURRENT_ACTUAL_UPB']<120000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=100000) & (df['CURRENT_ACTUAL_UPB']<110000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=90000) & (df['CURRENT_ACTUAL_UPB']<100000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=80000) & (df['CURRENT_ACTUAL_UPB']<90000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=70000) & (df['CURRENT_ACTUAL_UPB']<80000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=60000) & (df['CURRENT_ACTUAL_UPB']<70000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=50000) & (df['CURRENT_ACTUAL_UPB']<60000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=40000) & (df['CURRENT_ACTUAL_UPB']<50000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']>=30000) & (df['CURRENT_ACTUAL_UPB']<40000)].count()\n",
    "# df[(df['CURRENT_ACTUAL_UPB']<30000)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # iterate over the Remittance Files\n",
    "# for file in remitFiles:\n",
    "#     for y, q in [(y,q) for y in years for q in qtrs]:\n",
    "#         fileName = f'{file}{y}Q{q}.txt'\n",
    "#         print('Processing ' + fileName)\n",
    "#         loadDataFile(fileName, 'remittance', con, remit_columns, remit_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_sql(f\"select * from loans\", con)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_sql(f\"select * from remittance\", con)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readRemit(fileName):\n",
    "    remit_columns=['LOAN_NUMBER', 'MONTHLY_REPORTING_PERIOD', 'CURRENT_ACTUAL_UPB', 'DELINQUENCY_STATUS', 'LOAN_AGE', \\\n",
    "              'REMAINING_MONTHS_TO_MATURITY', 'REPURCHASE', 'MODIFICATION', 'ZERO_BALANCE_CODE', 'ZERO_BALANCE_EFFECTIVE_DATE', \\\n",
    "              'CURRENT_INTEREST_RATE', 'CURRENT_DEFERRED_UPB', 'DUE_DATE_OF_LAST_PAID_INSTALLMENT', \\\n",
    "              'MI_RECOVERIES', 'NET_SALES_PROCEEDS', 'NON_MI_RECOVERIES', 'EXPENSES', 'LEGAL_COSTS', 'MAINTENANCE_PRESERVATION_COSTS', \\\n",
    "              'TAXES_AND_INSURANCE', 'MISCELLANEOUS_EXPENSES', 'ACTUAL_LOSS_CALCULATION', 'MODIFICATION_COST', 'STEP_MODIFICATION',\\\n",
    "              'DEFERRED_PAYMENT_PLAN', 'ESTIMATED_LOAN_TO_VALUE', 'ZERO_BALANCE_REMOVAL_UPB', 'DELINQUENT_ACCRUED_INTEREST', \\\n",
    "              'DELINQUENCY_DUE_TO_DISASTER', 'BORROWER_ASSISTANCE_STATUS_CODE']\n",
    "    remit_data_type = {'MODIFICATION':str, 'REPURCHASE': str, 'DELINQUENCY_STATUS':str, 'LOAN_NUMBER':str, \\\n",
    "             'MONTHLY_REPORTING_PERIOD':'Int32', 'STEP_MODIFICATION':str, 'LOAN_AGE':'Int16', #'REMAINING_MONTHS_TO_MATURITY':'Int16',\\\n",
    "                   'ZERO_BALANCE_CODE':'Int16', 'ZERO_BALANCE_EFFECTIVE_DATE':'Int32', 'DUE_DATE_OF_LAST_PAID_INSTALLMENT':'Int32'\n",
    "                  }\n",
    "    df = pd.read_csv('data/' + fileName, delimiter='|', header=None, names=remit_columns, dtype = remit_data_type)\n",
    "    drop_columns = ['CURRENT_ACTUAL_UPB', 'LOAN_AGE',\\\n",
    "              'REMAINING_MONTHS_TO_MATURITY', 'REPURCHASE', 'MODIFICATION', 'ZERO_BALANCE_EFFECTIVE_DATE', \\\n",
    "              'CURRENT_INTEREST_RATE', 'CURRENT_DEFERRED_UPB', 'DUE_DATE_OF_LAST_PAID_INSTALLMENT', \\\n",
    "              'MI_RECOVERIES', 'NET_SALES_PROCEEDS', 'NON_MI_RECOVERIES', 'EXPENSES', 'LEGAL_COSTS', 'MAINTENANCE_PRESERVATION_COSTS', \\\n",
    "              'TAXES_AND_INSURANCE', 'MISCELLANEOUS_EXPENSES', 'ACTUAL_LOSS_CALCULATION', 'MODIFICATION_COST', 'STEP_MODIFICATION',\\\n",
    "              'DEFERRED_PAYMENT_PLAN', 'ESTIMATED_LOAN_TO_VALUE', 'ZERO_BALANCE_REMOVAL_UPB', 'DELINQUENT_ACCRUED_INTEREST', \\\n",
    "              'DELINQUENCY_DUE_TO_DISASTER', 'BORROWER_ASSISTANCE_STATUS_CODE']\n",
    "    df.drop(drop_columns, inplace=True, axis=1) # only keep a couple of columns to keep memory usage low\n",
    "    # only keep the most recent monthly reporting period record to get the delinquency status to keep memory usage low\n",
    "    df.sort_values(['LOAN_NUMBER','MONTHLY_REPORTING_PERIOD'], ascending=[True, False], inplace=True)\n",
    "    df.drop_duplicates(['LOAN_NUMBER'], keep='first', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remitFiles = ['historical_data_excl_time_','historical_data_time_'] # 1999Q1\n",
    "years = range(1999, 2004) # 2005\n",
    "qtrs = range(1,5)\n",
    "\n",
    "firstOne = True\n",
    "# iterate over the Remittance Files\n",
    "for file in remitFiles:\n",
    "    for y, q in [(y,q) for y in years for q in qtrs]:\n",
    "        fileName = f'{file}{y}Q{q}.txt'\n",
    "        print('Processing ' + fileName)\n",
    "        df1 = readRemit(fileName)\n",
    "        # Dataframe gets too big for memory to handle\n",
    "        # write out to csv\n",
    "        df1.to_csv('data/remit.csv', header=False, index=False, mode='a')\n",
    "#         if firstOne:\n",
    "#             dfRemit = df1\n",
    "#             firstOne = False\n",
    "#         else:\n",
    "#             dfRemit = pd.concat([dfRemit, df1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End up appending time series data into csv file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
